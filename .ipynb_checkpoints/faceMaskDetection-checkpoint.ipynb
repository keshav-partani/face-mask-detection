{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf31e8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 20:25:51.378975: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b00bdf9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 20:25:55.267654: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-03-19 20:25:55.270556: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2024-03-19 20:25:56.818023: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-19 20:25:56.818220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1650 computeCapability: 7.5\n",
      "coreClock: 1.515GHz coreCount: 14 deviceMemorySize: 3.81GiB deviceMemoryBandwidth: 178.84GiB/s\n",
      "2024-03-19 20:25:56.818242: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-03-19 20:25:56.852970: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2024-03-19 20:25:56.853206: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2024-03-19 20:25:56.876578: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-03-19 20:25:56.881738: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-03-19 20:25:56.921356: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-03-19 20:25:56.928831: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-03-19 20:25:56.999078: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-03-19 20:25:56.999518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-19 20:25:57.000122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-19 20:25:57.000470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# sess = tf.Session(config=config)\n",
    "    \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ca48cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3a0d8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['with_mask', 'without_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aca1011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for category in categories:\n",
    "    image_folders = os.path.join(\"dataset/train\", category)\n",
    "    \n",
    "    label = categories.index(category)\n",
    "    \n",
    "    for file in os.listdir(image_folders):\n",
    "        img_path = os.path.join(image_folders , file)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (224,224))\n",
    "        \n",
    "        data.append([img, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67b16b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1279"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bd8a38",
   "metadata": {},
   "source": [
    "###  To shuffel my data so that all with_mask not on the top only and Numpy to convert list to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e113e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21749b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2605bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "\n",
    "for features, label in data:\n",
    "    x.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bec2f34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "1279\n"
     ]
    }
   ],
   "source": [
    "print(len(x))\n",
    "print(len(y))\n",
    "# print(x.shape)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3519f29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e81feba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1279, 224, 224, 3)\n",
      "(1279,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e4e4790",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[201, 210, 220],\n",
       "        [201, 211, 221],\n",
       "        [202, 212, 222],\n",
       "        ...,\n",
       "        [226, 242, 249],\n",
       "        [223, 239, 246],\n",
       "        [226, 242, 249]],\n",
       "\n",
       "       [[201, 210, 220],\n",
       "        [204, 214, 222],\n",
       "        [203, 214, 222],\n",
       "        ...,\n",
       "        [228, 244, 251],\n",
       "        [227, 243, 250],\n",
       "        [226, 242, 248]],\n",
       "\n",
       "       [[201, 212, 219],\n",
       "        [198, 209, 216],\n",
       "        [201, 214, 220],\n",
       "        ...,\n",
       "        [228, 244, 251],\n",
       "        [228, 244, 251],\n",
       "        [228, 245, 248]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[200, 207, 210],\n",
       "        [209, 216, 219],\n",
       "        [217, 224, 227],\n",
       "        ...,\n",
       "        [182, 165, 211],\n",
       "        [187, 175, 220],\n",
       "        [169, 156, 194]],\n",
       "\n",
       "       [[206, 213, 216],\n",
       "        [213, 220, 223],\n",
       "        [214, 221, 224],\n",
       "        ...,\n",
       "        [182, 172, 212],\n",
       "        [164, 156, 196],\n",
       "        [175, 166, 201]],\n",
       "\n",
       "       [[206, 213, 216],\n",
       "        [212, 219, 223],\n",
       "        [214, 221, 224],\n",
       "        ...,\n",
       "        [186, 174, 215],\n",
       "        [194, 187, 221],\n",
       "        [186, 184, 213]]], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ac0424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to standarize x\n",
    "x = x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a55f1ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.78823529, 0.82352941, 0.8627451 ],\n",
       "        [0.78823529, 0.82745098, 0.86666667],\n",
       "        [0.79215686, 0.83137255, 0.87058824],\n",
       "        ...,\n",
       "        [0.88627451, 0.94901961, 0.97647059],\n",
       "        [0.8745098 , 0.9372549 , 0.96470588],\n",
       "        [0.88627451, 0.94901961, 0.97647059]],\n",
       "\n",
       "       [[0.78823529, 0.82352941, 0.8627451 ],\n",
       "        [0.8       , 0.83921569, 0.87058824],\n",
       "        [0.79607843, 0.83921569, 0.87058824],\n",
       "        ...,\n",
       "        [0.89411765, 0.95686275, 0.98431373],\n",
       "        [0.89019608, 0.95294118, 0.98039216],\n",
       "        [0.88627451, 0.94901961, 0.97254902]],\n",
       "\n",
       "       [[0.78823529, 0.83137255, 0.85882353],\n",
       "        [0.77647059, 0.81960784, 0.84705882],\n",
       "        [0.78823529, 0.83921569, 0.8627451 ],\n",
       "        ...,\n",
       "        [0.89411765, 0.95686275, 0.98431373],\n",
       "        [0.89411765, 0.95686275, 0.98431373],\n",
       "        [0.89411765, 0.96078431, 0.97254902]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.78431373, 0.81176471, 0.82352941],\n",
       "        [0.81960784, 0.84705882, 0.85882353],\n",
       "        [0.85098039, 0.87843137, 0.89019608],\n",
       "        ...,\n",
       "        [0.71372549, 0.64705882, 0.82745098],\n",
       "        [0.73333333, 0.68627451, 0.8627451 ],\n",
       "        [0.6627451 , 0.61176471, 0.76078431]],\n",
       "\n",
       "       [[0.80784314, 0.83529412, 0.84705882],\n",
       "        [0.83529412, 0.8627451 , 0.8745098 ],\n",
       "        [0.83921569, 0.86666667, 0.87843137],\n",
       "        ...,\n",
       "        [0.71372549, 0.6745098 , 0.83137255],\n",
       "        [0.64313725, 0.61176471, 0.76862745],\n",
       "        [0.68627451, 0.65098039, 0.78823529]],\n",
       "\n",
       "       [[0.80784314, 0.83529412, 0.84705882],\n",
       "        [0.83137255, 0.85882353, 0.8745098 ],\n",
       "        [0.83921569, 0.86666667, 0.87843137],\n",
       "        ...,\n",
       "        [0.72941176, 0.68235294, 0.84313725],\n",
       "        [0.76078431, 0.73333333, 0.86666667],\n",
       "        [0.72941176, 0.72156863, 0.83529412]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc0699d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b02a2c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = tts(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23b2952f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1023, 224, 224, 3)\n",
      "(1023,)\n",
      "(256, 224, 224, 3)\n",
      "(256,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c2ebdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8ab0220",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vgg = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbd85f12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffa997ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "faffc563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb429c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in vgg.layers[:-1]:\n",
    "#     model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a35f653",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5163f9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in model.layers:\n",
    "#     layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d66d6930",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "148260ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed0173b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85684bd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2ecc9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ae9df4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.fit(X_train, y_train, epochs=5 , validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e69780d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9ebc08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddc1d011",
   "metadata": {},
   "source": [
    "# without vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94b7393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b26b6fd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-19 20:26:29.336107: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-19 20:26:29.337148: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2024-03-19 20:26:29.337485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-19 20:26:29.337952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1650 computeCapability: 7.5\n",
      "coreClock: 1.515GHz coreCount: 14 deviceMemorySize: 3.81GiB deviceMemoryBandwidth: 178.84GiB/s\n",
      "2024-03-19 20:26:29.338010: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-03-19 20:26:29.338098: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2024-03-19 20:26:29.338181: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2024-03-19 20:26:29.338235: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2024-03-19 20:26:29.338282: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2024-03-19 20:26:29.338327: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2024-03-19 20:26:29.338372: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2024-03-19 20:26:29.338417: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-03-19 20:26:29.338601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-19 20:26:29.339066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-19 20:26:29.339391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2024-03-19 20:26:29.339855: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2024-03-19 20:26:30.431923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-03-19 20:26:30.431957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2024-03-19 20:26:30.431964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2024-03-19 20:26:30.435714: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-19 20:26:30.435921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-19 20:26:30.436049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-03-19 20:26:30.436158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3399 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c672e5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(224,224,3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1704cd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39eb86a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 16)        4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2769152   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,779,121\n",
      "Trainable params: 2,779,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d10cc3cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 2s 48ms/step - loss: 6.1313e-04 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 0.9844\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 2.5299e-04 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9805\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 1.7300e-04 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 0.9805\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 1s 44ms/step - loss: 1.3351e-04 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 0.9883\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 1.0713e-04 - accuracy: 1.0000 - val_loss: 0.0549 - val_accuracy: 0.9844\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 8.7830e-05 - accuracy: 1.0000 - val_loss: 0.0553 - val_accuracy: 0.9844\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 7.4190e-05 - accuracy: 1.0000 - val_loss: 0.0552 - val_accuracy: 0.9883\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 6.2573e-05 - accuracy: 1.0000 - val_loss: 0.0587 - val_accuracy: 0.9844\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 5.4201e-05 - accuracy: 1.0000 - val_loss: 0.0598 - val_accuracy: 0.9844\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.6792e-05 - accuracy: 1.0000 - val_loss: 0.0597 - val_accuracy: 0.9844\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 1s 40ms/step - loss: 4.0732e-05 - accuracy: 1.0000 - val_loss: 0.0603 - val_accuracy: 0.9844\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 3.7906e-05 - accuracy: 1.0000 - val_loss: 0.0641 - val_accuracy: 0.9844\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 3.1975e-05 - accuracy: 1.0000 - val_loss: 0.0625 - val_accuracy: 0.9844\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 2.9284e-05 - accuracy: 1.0000 - val_loss: 0.0623 - val_accuracy: 0.9844\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 2.5930e-05 - accuracy: 1.0000 - val_loss: 0.0640 - val_accuracy: 0.9844\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 2.3295e-05 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 0.9844\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 2.1407e-05 - accuracy: 1.0000 - val_loss: 0.0631 - val_accuracy: 0.9844\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 1s 43ms/step - loss: 1.9316e-05 - accuracy: 1.0000 - val_loss: 0.0651 - val_accuracy: 0.9844\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 1.7658e-05 - accuracy: 1.0000 - val_loss: 0.0666 - val_accuracy: 0.9844\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 1s 42ms/step - loss: 1.6445e-05 - accuracy: 1.0000 - val_loss: 0.0658 - val_accuracy: 0.9844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7aaf78552f50>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20 , validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2223462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad638742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5f4b7b8",
   "metadata": {},
   "source": [
    "# for video prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8d8c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93e39b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face_mask(img):\n",
    "    y_pred = model.predict_classes(img.reshape(1,224,224,3))\n",
    "                           \n",
    "    return y_pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d753242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_label(img, text, pos, bg_color):\n",
    "    \n",
    "    text_size = cv2.getTextSize(text,cv2.FONT_HERSHEY_SIMPLEX,1,cv2.FILLED)\n",
    "    \n",
    "    end_x = pos[0] + text_size[0][0] + 2\n",
    "    end_y = pos[1] + text_size[0][1] - 2\n",
    "    \n",
    "    cv2.rectangle(img,pos,(end_x,end_y),bg_color, cv2.FILLED)\n",
    "    cv2.putText(img,text,pos,cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,0), 1, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983a0440",
   "metadata": {},
   "outputs": [],
   "source": [
    "haar = cv2.CascadeClassifier('Haarcascae/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d042d417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(img):\n",
    "    cordinates = haar.detectMultiScale(img)\n",
    "    return cordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b9cba15a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@243.081] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n",
      "[ WARN:0@243.081] global /croot/opencv-suite_1676452025216/work/modules/videoio/src/cap_v4l.cpp (902) open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot open camera\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) /croot/opencv-suite_1676452025216/work/modules/imgproc/src/resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_58543/2788944922.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_face_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /croot/opencv-suite_1676452025216/work/modules/imgproc/src/resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    img = cv2.resize(frame, (224,224))\n",
    "    \n",
    "    y_pred = detect_face_mask(img)\n",
    "    print(y_pred)\n",
    "    \n",
    "    if y_pred == 0:\n",
    "        draw_label(frame, \"Mask detect\",(30,30),(0,255,0))\n",
    "    else:\n",
    "        draw_label(frame, \"No Mask detect\",(30,30),(255,0,0))\n",
    "        \n",
    "    \n",
    "    #for rectangle in detection    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    cord = detect_face(gray)\n",
    "    \n",
    "    for x,y,w,h in cord:\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,0), 4)\n",
    "    \n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "        \n",
    "    # Our operations on the frame come here\n",
    "#     gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('window', frame)\n",
    "    if cv2.waitKey(1) == ord('x'):\n",
    "        break\n",
    "        \n",
    " # When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeefa5cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl_project] *",
   "language": "python",
   "name": "conda-env-dl_project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
